{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Collecting latest 50 car ad links...\n",
      "[INFO] Collected 40 links into car_links_test.txt\n",
      "[INFO] Found 40 links in car_links_test.txt. Starting scrape...\n",
      "[SKIP] Already scraped: cars_test\\Volvo V90 Cross Country D5 AWD Geartronic Momentum Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Toyota Corolla Hybrid e-CVT Executive Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Citroën\n",
      "[SKIP] Already scraped: cars_test\\BMW X5 xDrive40e laddhybrid M Sport H_K Läder Navi\n",
      "[SKIP] Already scraped: cars_test\\Kia Sportage PHEV Advance Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volvo V90 D3 Business, Kinetic Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Kia Picanto\n",
      "[SKIP] Already scraped: cars_test\\Volkswagen Tiguan Allspace 2.0 TDI 4Motion R-Line 7-Sits\n",
      "[SKIP] Already scraped: cars_test\\Nissan Qashqai 1.6 dCi XTRONIC-CVT Euro 5\n",
      "[SKIP] Already scraped: cars_test\\Hyundai Kona Electric 64 kWh Advanced, Trend\n",
      "[SKIP] Already scraped: cars_test\\Toyota Prius+ Hybrid CVT Euro 6\n",
      "[SKIP] Already scraped: cars_test\\BMW 330e Touring Steptronic Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Audi A5 Sportback 2.0 TDI quattro S Tronic Proline, S Line E\n",
      "[SKIP] Already scraped: cars_test\\BMW 435 i Coupé M Sport 380hk Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Tesla Model 3 Long Range AWD, drag, Acc boost, välskött\n",
      "[SKIP] Already scraped: cars_test\\BMW 530d XDrive Steptronic M Sport _ 320hk\n",
      "[SKIP] Already scraped: cars_test\\Cupra Formentor VZ e-Hybrid - Överlåtelse privatleasing\n",
      "[SKIP] Already scraped: cars_test\\Land Rover Discovery Sport\n",
      "[SKIP] Already scraped: cars_test\\Citroën Berlingo 1.5 Blue Hdi 2019\n",
      "[SKIP] Already scraped: cars_test\\Ford Galaxy 2.0 TDCi Powershift Business Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volvo V90 D3 Geartronic Business, Kinetic Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volkswagen Golf Sportsvan 1.2 TSI BMT Masters Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Audi A4 Avant 2.0 TDI S Tronic Proline Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volvo V60 D2 Kinetic Euro 5\n",
      "[SKIP] Already scraped: cars_test\\Ford transit 350 2.0 TDCi AWD Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Ford Focus Kombi 1.0 EcoBoost Titanium Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volkswagen Golf 5-dörrars R 2.0 TSI BMT 4Motion R Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Volkswagen Tiguan 1.4 TSI 4Motion Sport & Style Euro 5\n",
      "[SKIP] Already scraped: cars_test\\BMW 320d xDrive Touring Aut M Sport Elstol Drag H_K Pano HUD\n",
      "[SKIP] Already scraped: cars_test\\Citroën Jumpy NYA FACELIFT - Automat, drag\n",
      "[SKIP] Already scraped: cars_test\\Citroën C3 1.2 VTi Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Toyota ProAce City 1.2 Turbo Euro 6\n",
      "[SKIP] Already scraped: cars_test\\Kia Carens 1.7 CRDi DCT GLS psen 7sits Eu6\n",
      "[SKIP] Already scraped: cars_test\\Mercedes-Benz CLS 250 BlueTEC\n",
      "[DONE] Scraped 6 new ads, skipped 34 existing ones.\n",
      "[CLEANUP DONE] Removed 0 folders. 439 kept.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import shutil\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- Constants and URLs ---\n",
    "START_URL = (\n",
    "    \"https://www.blocket.se/bilar/sok?\"\n",
    "    \"filter=%7B\\\"key\\\"%3A\\\"modelYear\\\"%2C\\\"range\\\"%3A%7B\\\"start\\\"%3A\\\"2015\\\"%2C\\\"end\\\"%3A\\\"\\\"%7D%7D&\"\n",
    "    \"filter=%7B\\\"key\\\"%3A\\\"sellerType\\\"%2C\\\"values\\\"%3A%5B\\\"Privat\\\"%5D%7D\"\n",
    ")\n",
    "CARS_FOLDER = \"cars_test\"\n",
    "LINKS_FILE = \"car_links_test.txt\"\n",
    "CHROME_PATH = r\"C:\\Users\\gisse\\Downloads\\chrome-win64\\chrome-win64\\chrome.exe\"\n",
    "DRIVER_PATH = r\"C:\\Users\\gisse\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"\n",
    "CHROME_VERSION = 135\n",
    "\n",
    "# --- Chrome Options and Driver Setup ---\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.binary_location = CHROME_PATH\n",
    "\n",
    "driver = uc.Chrome(\n",
    "    driver_executable_path=DRIVER_PATH,\n",
    "    browser_executable_path=CHROME_PATH,\n",
    "    version_main=CHROME_VERSION,\n",
    "    options=options\n",
    ")\n",
    " \n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# --- Utilities ---\n",
    "def sanitize_filename(s):\n",
    "    return re.sub(r'[\\\\/:*?\\\"<>|]+', '_', s)\n",
    "\n",
    "def bypass_cookies():\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe[id^='sp_message_iframe_']\"))\n",
    "        )\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.sp_choice_type_11\"))\n",
    "        ).click()\n",
    "        driver.switch_to.default_content()\n",
    "    except:\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "def extract_price():\n",
    "    try:\n",
    "        el = driver.find_element(By.CSS_SELECTOR, \"div[class*='Price__StyledPrice']\")\n",
    "        return re.sub(r\"\\D\", \"\", el.text.strip()) or \"N/A\"\n",
    "    except:\n",
    "        return \"N/A\"\n",
    "\n",
    "def get_ad_details():\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"article\"))\n",
    "    )\n",
    "    try:\n",
    "        title = driver.find_element(By.CSS_SELECTOR, \"h1\").text.strip()\n",
    "    except:\n",
    "        title = \"UnknownTitle\"\n",
    "    return title, extract_price()\n",
    "\n",
    "def save_carousel_images(folder):\n",
    "    CSS_DIVS = \"article div[style*='background-image']\"\n",
    "    CSS_NEXT_BTN = \"button.SliderControls__StyledButton-sc-1dbsnpt-4.cIKvvT\"\n",
    "    all_urls, prev_count = set(), 0\n",
    "\n",
    "    for _ in range(25):\n",
    "        divs = driver.find_elements(By.CSS_SELECTOR, CSS_DIVS)\n",
    "        for d in divs:\n",
    "            style = d.get_attribute(\"style\")\n",
    "            m = re.search(r'url\\(\"([^\"]+)\"\\)', style)\n",
    "            if m:\n",
    "                all_urls.add(m.group(1))\n",
    "        if len(all_urls) == prev_count:\n",
    "            break\n",
    "        prev_count = len(all_urls)\n",
    "        try:\n",
    "            btn = driver.find_element(By.CSS_SELECTOR, CSS_NEXT_BTN)\n",
    "            if btn.is_enabled() and btn.is_displayed():\n",
    "                btn.click()\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    for i, url in enumerate(all_urls, 1):\n",
    "        img_path = os.path.join(folder, f\"img_{i}.jpg\")\n",
    "        try:\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(requests.get(url).content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save image from {url}: {e}\")\n",
    "\n",
    "def save_parameters(folder):\n",
    "    try:\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div[class*='ExpandableContent__Content']\"))\n",
    "        )\n",
    "        labels = driver.find_elements(By.CSS_SELECTOR, \"div[class*='ParamsWithIcons__StyledLabel']\")\n",
    "        values = driver.find_elements(By.CSS_SELECTOR, \"div[class*='ParamsWithIcons__StyledParamValue']\")\n",
    "        for i in range(min(len(labels), len(values))):\n",
    "            lbl = labels[i].text.strip() or f\"NoLabel_{i}\"\n",
    "            val = values[i].text.strip() or \"N/A\"\n",
    "            fn = sanitize_filename(lbl)\n",
    "            with open(os.path.join(folder, f\"{fn}.txt\"), \"w\", encoding=\"utf-8\") as ff:\n",
    "                ff.write(val)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def scrape_single_ad(url):\n",
    "    driver.get(url)\n",
    "    bypass_cookies()\n",
    "    title, price = get_ad_details()\n",
    "    folder_name = sanitize_filename(title)[:80] or \"NoTitle\"\n",
    "    folder = os.path.join(CARS_FOLDER, folder_name)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(folder, \"price.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(price)\n",
    "    with open(os.path.join(folder, \"url.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(url)\n",
    "\n",
    "    save_carousel_images(folder)\n",
    "    save_parameters(folder)\n",
    "\n",
    "def collect_latest_links(n=50):\n",
    "    print(f\"[INFO] Collecting latest {n} car ad links...\")\n",
    "    driver.get(START_URL)\n",
    "    bypass_cookies()\n",
    "\n",
    "    collected = set()\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    MAX_SCROLLS = 10\n",
    "\n",
    "    for _ in range(MAX_SCROLLS):\n",
    "        ads = driver.find_elements(By.CSS_SELECTOR, \"div.list.w-full > div > a\")\n",
    "        for ad in ads:\n",
    "            href = ad.get_attribute(\"href\")\n",
    "            if href and href.startswith(\"https://www.blocket.se/annons/\") and href not in collected:\n",
    "                collected.add(href)\n",
    "                if len(collected) >= n:\n",
    "                    break\n",
    "        if len(collected) >= n:\n",
    "            break\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    with open(LINKS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        for link in list(collected)[:n]:\n",
    "            f.write(link + \"\\n\")\n",
    "\n",
    "    print(f\"[INFO] Collected {len(collected)} links into {LINKS_FILE}\")\n",
    "\n",
    "def scrape_from_file():\n",
    "    if not os.path.exists(LINKS_FILE):\n",
    "        print(f\"[ERROR] File {LINKS_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    with open(LINKS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_links = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    print(f\"[INFO] Found {len(all_links)} links in {LINKS_FILE}. Starting scrape...\")\n",
    "    os.makedirs(CARS_FOLDER, exist_ok=True)\n",
    "\n",
    "    skipped = 0\n",
    "    scraped = 0\n",
    "\n",
    "    for link in all_links:\n",
    "        try:\n",
    "            driver.get(link)\n",
    "            bypass_cookies()\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1\"))\n",
    "            )\n",
    "            title = driver.find_element(By.CSS_SELECTOR, \"h1\").text.strip()\n",
    "            folder_name = sanitize_filename(title)[:80] or \"NoTitle\"\n",
    "            folder = os.path.join(CARS_FOLDER, folder_name)\n",
    "\n",
    "            if os.path.exists(os.path.join(folder, \"url.txt\")):\n",
    "                skipped += 1\n",
    "                print(f\"[SKIP] Already scraped: {folder}\")\n",
    "                continue\n",
    "\n",
    "            scrape_single_ad(link)\n",
    "            scraped += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {link} -> {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"[DONE] Scraped {scraped} new ads, skipped {skipped} existing ones.\")\n",
    "\n",
    "def remove_dirs_with_slap(cars_folder=\"cars_test\"):\n",
    "    removed_count = 0\n",
    "    total_count = 0\n",
    "    for root, dirs, files in os.walk(cars_folder):\n",
    "        if \"Biltyp.txt\" in files:\n",
    "            total_count += 1\n",
    "            file_path = os.path.join(root, \"Biltyp.txt\")\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                    if any(x in content for x in [\"Släp\", \"Slap\", \"Husvagn\", \"Vagn\", \"Husbil\"]):\n",
    "                        print(f\"[REMOVE] {root}\")\n",
    "                        shutil.rmtree(root)\n",
    "                        removed_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Failed to read or delete {file_path}: {e}\")\n",
    "    print(f\"[CLEANUP DONE] Removed {removed_count} folders. {total_count - removed_count} kept.\")\n",
    "\n",
    "def main():\n",
    "    collect_latest_links(n=50)\n",
    "    scrape_from_file()\n",
    "    remove_dirs_with_slap()\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting undetected-chromedriver\n",
      "  Using cached undetected_chromedriver-3.5.5-py3-none-any.whl\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (6.29.5)\n",
      "Collecting websockets\n",
      "  Downloading websockets-15.0.1-cp39-cp39-win_amd64.whl (176 kB)\n",
      "Collecting urllib3[socks]<3,>=1.26\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Collecting certifi>=2021.10.8\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting websocket-client~=1.8\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (4.13.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: psutil in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.50)\n",
      "Requirement already satisfied: decorator in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-client>=6.1.12->ipykernel) (8.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (310)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting attrs>=23.2.0\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting cffi>=1.14\n",
      "  Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\gisse\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Installing collected packages: pycparser, attrs, sortedcontainers, sniffio, outcome, idna, h11, cffi, wsproto, urllib3, trio, pysocks, websocket-client, trio-websocket, charset-normalizer, certifi, websockets, selenium, requests, undetected-chromedriver\n",
      "Successfully installed attrs-25.3.0 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 h11-0.14.0 idna-3.10 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 requests-2.32.3 selenium-4.31.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 undetected-chromedriver-3.5.5 urllib3-2.4.0 websocket-client-1.8.0 websockets-15.0.1 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\gisse\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install undetected-chromedriver selenium requests ipykernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
